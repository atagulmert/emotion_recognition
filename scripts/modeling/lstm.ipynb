{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count=  124800\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, GlobalAveragePooling1D, Reshape, Flatten, BatchNormalization, LSTM\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import Imputer, OneHotEncoder, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "_script_path = Path().absolute() #location of our script\n",
    "_dataset_folder_name = 'Filtered_Dataframes'\n",
    "_dataset_folder_path = os.path.join(str(_script_path), _dataset_folder_name)\n",
    "\n",
    "_file_names = []\n",
    "_folder_locations = []  \n",
    "_dataset_list = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(_dataset_folder_path):\n",
    "    for filename in [f for f in filenames if f.endswith(\".csv\")]:\n",
    "        location = os.path.join(dirpath, filename)\n",
    "        _folder_locations.append(location)\n",
    "        _file_names.append(filename)\n",
    "\n",
    "for i,location in enumerate(_folder_locations):\n",
    "    temp_df = pd.read_csv(location,engine='python')\n",
    "    values = temp_df.iloc[:,0].values\n",
    "    values = values.reshape((len(values), 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(values)\n",
    "    normalized = scaler.transform(values)\n",
    "    temp_df = temp_df.drop(['ecg'],axis = 1)\n",
    "    temp_df['ecg'] = normalized\n",
    "    temp_df = temp_df.truncate(after = 399)\n",
    "    temp_df['participant_no'] = i\n",
    "    if \"anger\" in location:\n",
    "        temp_df['emotion'] = 0\n",
    "    elif \"calmness\" in location:\n",
    "        temp_df['emotion'] = 1\n",
    "    elif \"disgust\" in location:\n",
    "        temp_df['emotion'] = 2\n",
    "    elif \"fear\" in location:\n",
    "        temp_df['emotion'] = 3\n",
    "    elif \"happiness\" in location:\n",
    "        temp_df['emotion'] = 4\n",
    "    elif \"sadness\" in location:\n",
    "        temp_df['emotion'] = 5\n",
    "    unc_columns = ['hr','spo2','timest','temp']\n",
    "    temp_df = temp_df.drop(unc_columns,axis=1)\n",
    "    _dataset_list.append(temp_df)\n",
    "\n",
    "_dataset = pd.concat(_dataset_list,axis=0)\n",
    "_dataset.index = range(0,len(_dataset))\n",
    "_dataset = _dataset.sample(frac=1).reset_index(drop=True)\n",
    "train_x = _dataset.iloc[:,0:2]\n",
    "#train_x = train_x.drop(['participant_no'],axis=1)\n",
    "train_y = _dataset.iloc[:,3:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "\n",
    "print('Row count= ', len(_dataset))\n",
    "\n",
    "train_x = train_x.reshape(312,400,2)\n",
    "train_y = train_y.values.reshape(312,400)\n",
    "trunc_train_y = train_y[:,:1]\n",
    "\n",
    "train_y_enc = pd.DataFrame(trunc_train_y)\n",
    "train_y_enc = pd.get_dummies(train_y_enc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f3a051055f8>>\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/10\n",
      "209/209 [==============================] - 7s 31ms/step - loss: 1.7996 - acc: 0.1818 - val_loss: 1.7923 - val_acc: 0.1748\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.7960 - acc: 0.1675 - val_loss: 1.7923 - val_acc: 0.1748\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.7967 - acc: 0.1483 - val_loss: 1.7923 - val_acc: 0.1748\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.7973 - acc: 0.1292 - val_loss: 1.7924 - val_acc: 0.1748\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.8018 - acc: 0.1531 - val_loss: 1.7924 - val_acc: 0.1748\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.8010 - acc: 0.1579 - val_loss: 1.7924 - val_acc: 0.1748\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.7976 - acc: 0.1531 - val_loss: 1.7924 - val_acc: 0.1748\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.7972 - acc: 0.1292 - val_loss: 1.7925 - val_acc: 0.1748\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.7980 - acc: 0.1435 - val_loss: 1.7925 - val_acc: 0.1748\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 0s 2ms/step - loss: 1.7983 - acc: 0.1483 - val_loss: 1.7925 - val_acc: 0.1748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a0511a588>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20,input_shape=(400,2),dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#sgd = keras.optimizers.SGD(lr=0.000001, clipvalue=0.5)\n",
    "adagrad = keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.09, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "model.fit(train_x,train_y_enc,epochs = 10, batch_size = 312, validation_split=0.33, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(train_x)\n",
    "predict = predict.tolist()\n",
    "predict_labels = []\n",
    "for i in range(len(predict)):\n",
    "    predict_labels.append(predict[i].index(max(predict[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "0\n",
      "26\n",
      "133\n",
      "4\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print(predict_labels.count(0))\n",
    "print(predict_labels.count(1))\n",
    "print(predict_labels.count(2))\n",
    "print(predict_labels.count(3))\n",
    "print(predict_labels.count(4))\n",
    "print(predict_labels.count(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
