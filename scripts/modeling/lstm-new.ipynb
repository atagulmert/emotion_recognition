{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mert/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/mert/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count=  5616000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, GlobalAveragePooling1D, Reshape, Flatten, BatchNormalization, LSTM\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import Imputer, OneHotEncoder, StandardScaler\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "_script_path = Path().absolute() #location of our script\n",
    "_dataset_folder_name = 'filtered_data'\n",
    "_dataset_folder_path = os.path.join(str(_script_path), _dataset_folder_name)\n",
    "\n",
    "_file_names = []\n",
    "_folder_locations = []  \n",
    "_dataset_list = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(_dataset_folder_path):\n",
    "    for filename in [f for f in filenames if f.endswith(\".csv\")]:\n",
    "        location = os.path.join(dirpath, filename)\n",
    "        _folder_locations.append(location)\n",
    "        _file_names.append(filename)\n",
    "\n",
    "for i,location in enumerate(_folder_locations):\n",
    "    temp_df = pd.read_csv(location,engine='python')\n",
    "    values = temp_df.iloc[:,0].values\n",
    "    values = values.reshape((len(values), 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(values)\n",
    "    normalized = scaler.transform(values)\n",
    "    temp_df = temp_df.drop(['ecg'],axis = 1)\n",
    "    temp_df['ecg'] = normalized\n",
    "    temp_df = temp_df.truncate(after = 17999)\n",
    "    temp_df['participant_no'] = i\n",
    "    if \"anger\" in location:\n",
    "        temp_df['emotion'] = 0\n",
    "    elif \"calmness\" in location:\n",
    "        temp_df['emotion'] = 1\n",
    "    elif \"disgust\" in location:\n",
    "        temp_df['emotion'] = 2\n",
    "    elif \"fear\" in location:\n",
    "        temp_df['emotion'] = 3\n",
    "    elif \"happiness\" in location:\n",
    "        temp_df['emotion'] = 4\n",
    "    elif \"sadness\" in location:\n",
    "        temp_df['emotion'] = 5\n",
    "    unc_columns = ['timest']\n",
    "    temp_df = temp_df.drop(unc_columns,axis=1)\n",
    "    _dataset_list.append(temp_df)\n",
    "\n",
    "_dataset = pd.concat(_dataset_list,axis=0)\n",
    "_dataset.index = range(0,len(_dataset))\n",
    "_dataset = _dataset.sample(frac=1).reset_index(drop=True)\n",
    "train_x = _dataset.iloc[:,0:5]\n",
    "#train_x = train_x.drop(['participant_no'],axis=1)\n",
    "train_y = _dataset.iloc[:,6:]\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "\n",
    "print('Row count= ', len(_dataset))\n",
    "\n",
    "train_x = train_x.reshape(312,18000,5)\n",
    "train_y = train_y.values.reshape(312,18000)\n",
    "trunc_train_y = train_y[:,:1]\n",
    "\n",
    "\n",
    "train_y_enc = pd.DataFrame(trunc_train_y)\n",
    "train_y_enc = pd.get_dummies(train_y_enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_list = []\n",
    "train_y_list = []\n",
    "previous_value = 0\n",
    "while previous_value<= 17599:\n",
    "    train_x_list.append(train_x[:,previous_value:previous_value+400,:])\n",
    "    #train_y_list.append(train_y_enc.values[previous_value:previous_value+400,:])\n",
    "    previous_value+=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 400, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_list[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7f3e4d61c5f8>>\n",
      "Training  0 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 8s 39ms/step - loss: 1.8389 - acc: 0.1579 - val_loss: 1.7866 - val_acc: 0.1262\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7802 - acc: 0.2392 - val_loss: 1.8269 - val_acc: 0.2039\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.6780 - acc: 0.2919 - val_loss: 1.9832 - val_acc: 0.2233\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.6263 - acc: 0.2967 - val_loss: 2.0148 - val_acc: 0.1456\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 21ms/step - loss: 1.4933 - acc: 0.3971 - val_loss: 2.2372 - val_acc: 0.1553\n",
      "Training  1 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 5s 22ms/step - loss: 2.0762 - acc: 0.1627 - val_loss: 1.8800 - val_acc: 0.1165\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7817 - acc: 0.1627 - val_loss: 1.8226 - val_acc: 0.1359\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7718 - acc: 0.1962 - val_loss: 1.8247 - val_acc: 0.1068\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7535 - acc: 0.2344 - val_loss: 1.8380 - val_acc: 0.0777\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7110 - acc: 0.2919 - val_loss: 1.9101 - val_acc: 0.0971\n",
      "Training  2 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.8252 - acc: 0.1770 - val_loss: 1.8575 - val_acc: 0.1068\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 5s 23ms/step - loss: 1.7913 - acc: 0.1675 - val_loss: 1.8477 - val_acc: 0.0971\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7742 - acc: 0.2201 - val_loss: 1.8327 - val_acc: 0.1359\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7441 - acc: 0.2632 - val_loss: 1.8307 - val_acc: 0.1262\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7092 - acc: 0.2823 - val_loss: 1.8770 - val_acc: 0.1553\n",
      "Training  3 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.8505 - acc: 0.1579 - val_loss: 1.8381 - val_acc: 0.1845\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7631 - acc: 0.2536 - val_loss: 1.8189 - val_acc: 0.1942\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7348 - acc: 0.2584 - val_loss: 1.8204 - val_acc: 0.2039\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.6679 - acc: 0.3397 - val_loss: 1.8630 - val_acc: 0.2039\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.5886 - acc: 0.3301 - val_loss: 1.9719 - val_acc: 0.1942\n",
      "Training  4 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.9297 - acc: 0.1675 - val_loss: 1.8981 - val_acc: 0.1068\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7963 - acc: 0.1818 - val_loss: 1.8222 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7476 - acc: 0.2201 - val_loss: 1.8245 - val_acc: 0.1748\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.6629 - acc: 0.3589 - val_loss: 1.8348 - val_acc: 0.1456\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.6486 - acc: 0.2727 - val_loss: 1.9643 - val_acc: 0.1456\n",
      "Training  5 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.8956 - acc: 0.1340 - val_loss: 1.8349 - val_acc: 0.1553\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7597 - acc: 0.2297 - val_loss: 1.8045 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7453 - acc: 0.2536 - val_loss: 1.8040 - val_acc: 0.2136\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7046 - acc: 0.2727 - val_loss: 1.8184 - val_acc: 0.2039\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.6125 - acc: 0.3254 - val_loss: 1.9105 - val_acc: 0.1845\n",
      "Training  6 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.9067 - acc: 0.1531 - val_loss: 1.8656 - val_acc: 0.1845\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7710 - acc: 0.1962 - val_loss: 1.8288 - val_acc: 0.1748\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7429 - acc: 0.2536 - val_loss: 1.8282 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.6910 - acc: 0.2967 - val_loss: 1.8287 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.6684 - acc: 0.3062 - val_loss: 2.0131 - val_acc: 0.1359\n",
      "Training  7 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 5s 24ms/step - loss: 1.9620 - acc: 0.1531 - val_loss: 1.8237 - val_acc: 0.1456\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 5s 22ms/step - loss: 1.8242 - acc: 0.1340 - val_loss: 1.8267 - val_acc: 0.1359\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.8008 - acc: 0.1722 - val_loss: 1.7979 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7892 - acc: 0.1914 - val_loss: 1.7988 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 5s 23ms/step - loss: 1.7882 - acc: 0.1483 - val_loss: 1.7985 - val_acc: 0.2039\n",
      "Training  8 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7860 - acc: 0.2153 - val_loss: 1.7997 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7878 - acc: 0.1818 - val_loss: 1.8069 - val_acc: 0.1359\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7887 - acc: 0.1579 - val_loss: 1.8110 - val_acc: 0.1748\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7881 - acc: 0.1627 - val_loss: 1.8119 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7867 - acc: 0.1962 - val_loss: 1.8160 - val_acc: 0.1650\n",
      "Training  9 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7879 - acc: 0.1866 - val_loss: 1.8146 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7869 - acc: 0.1914 - val_loss: 1.8114 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7901 - acc: 0.1914 - val_loss: 1.8052 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 21ms/step - loss: 1.7887 - acc: 0.1914 - val_loss: 1.8044 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7881 - acc: 0.1914 - val_loss: 1.8046 - val_acc: 0.1650\n",
      "Training  10 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7873 - acc: 0.1914 - val_loss: 1.8059 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7873 - acc: 0.1914 - val_loss: 1.8063 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7875 - acc: 0.1914 - val_loss: 1.8065 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7879 - acc: 0.1914 - val_loss: 1.8098 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7853 - acc: 0.1866 - val_loss: 1.8074 - val_acc: 0.1650\n",
      "Training  11 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7885 - acc: 0.1914 - val_loss: 1.8088 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7888 - acc: 0.1914 - val_loss: 1.8104 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7855 - acc: 0.1914 - val_loss: 1.8073 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7888 - acc: 0.1914 - val_loss: 1.8075 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7845 - acc: 0.1914 - val_loss: 1.8083 - val_acc: 0.1553\n",
      "Training  12 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7905 - acc: 0.1770 - val_loss: 1.8105 - val_acc: 0.1359\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7870 - acc: 0.1675 - val_loss: 1.8093 - val_acc: 0.1748\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7867 - acc: 0.1914 - val_loss: 1.8102 - val_acc: 0.1456\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7878 - acc: 0.1579 - val_loss: 1.8097 - val_acc: 0.1456\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7866 - acc: 0.1866 - val_loss: 1.8099 - val_acc: 0.1650\n",
      "Training  13 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7870 - acc: 0.1866 - val_loss: 1.8078 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7857 - acc: 0.1914 - val_loss: 1.8074 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7867 - acc: 0.1914 - val_loss: 1.8090 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7855 - acc: 0.1914 - val_loss: 1.8086 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7862 - acc: 0.1914 - val_loss: 1.8090 - val_acc: 0.1650\n",
      "Training  14 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7858 - acc: 0.1914 - val_loss: 1.8096 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7852 - acc: 0.1914 - val_loss: 1.8077 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7870 - acc: 0.1914 - val_loss: 1.8070 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7878 - acc: 0.1914 - val_loss: 1.8086 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7871 - acc: 0.1914 - val_loss: 1.8069 - val_acc: 0.1650\n",
      "Training  15 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 5s 22ms/step - loss: 1.7869 - acc: 0.1914 - val_loss: 1.8062 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7861 - acc: 0.1914 - val_loss: 1.8075 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 5s 23ms/step - loss: 1.7870 - acc: 0.1914 - val_loss: 1.8148 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 21ms/step - loss: 1.7787 - acc: 0.1914 - val_loss: 1.8150 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 21ms/step - loss: 1.7708 - acc: 0.1914 - val_loss: 1.8281 - val_acc: 0.1650\n",
      "Training  16 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 5s 24ms/step - loss: 1.8089 - acc: 0.1914 - val_loss: 1.7873 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7897 - acc: 0.1914 - val_loss: 1.8051 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7874 - acc: 0.1914 - val_loss: 1.8053 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7872 - acc: 0.1914 - val_loss: 1.8060 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7872 - acc: 0.1914 - val_loss: 1.8058 - val_acc: 0.1650\n",
      "Training  17 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7868 - acc: 0.1914 - val_loss: 1.8064 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7868 - acc: 0.1914 - val_loss: 1.8066 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7871 - acc: 0.1914 - val_loss: 1.8065 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 21ms/step - loss: 1.7866 - acc: 0.1914 - val_loss: 1.8074 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 5s 23ms/step - loss: 1.7867 - acc: 0.1914 - val_loss: 1.8101 - val_acc: 0.1650\n",
      "Training  18 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7863 - acc: 0.1962 - val_loss: 1.8073 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7864 - acc: 0.1914 - val_loss: 1.8067 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7865 - acc: 0.1914 - val_loss: 1.8069 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7872 - acc: 0.1914 - val_loss: 1.8079 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 5s 22ms/step - loss: 1.7868 - acc: 0.1914 - val_loss: 1.8076 - val_acc: 0.1650\n",
      "Training  19 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 5s 22ms/step - loss: 1.7866 - acc: 0.1914 - val_loss: 1.8081 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 5s 25ms/step - loss: 1.7868 - acc: 0.1914 - val_loss: 1.8075 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7868 - acc: 0.1914 - val_loss: 1.8082 - val_acc: 0.1650\n",
      "Epoch 4/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7869 - acc: 0.1914 - val_loss: 1.8080 - val_acc: 0.1650\n",
      "Epoch 5/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7871 - acc: 0.1914 - val_loss: 1.8076 - val_acc: 0.1650\n",
      "Training  20 th window.\n",
      "Train on 209 samples, validate on 103 samples\n",
      "Epoch 1/5\n",
      "209/209 [==============================] - 4s 19ms/step - loss: 1.7868 - acc: 0.1914 - val_loss: 1.8087 - val_acc: 0.1650\n",
      "Epoch 2/5\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 1.7870 - acc: 0.1914 - val_loss: 1.8087 - val_acc: 0.1650\n",
      "Epoch 3/5\n",
      "192/209 [==========================>...] - ETA: 0s - loss: 1.7872 - acc: 0.1927"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(5,100,activation='relu',input_shape=(400,5)))\n",
    "model.add(LSTM(32,return_sequences=True,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(LSTM(64,return_sequences=True,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(LSTM(32,return_sequences=False))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "print(model.summary)\n",
    "\n",
    "rmsprop = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "#sgd = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "sgd = keras.optimizers.SGD(lr=0.000001, clipvalue=0.5)\n",
    "adagrad = keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "for i in range(50):\n",
    "    print('Training ', i, 'th window.')\n",
    "    history = model.fit(train_x_list[i],train_y_enc,epochs = 5, batch_size = 32, validation_split=0.33)\n",
    "    #model.reset_states()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = model.predict(train_x_list[153])\n",
    "predict = predict.tolist()\n",
    "predict_labels = []\n",
    "for i in range(len(predict)):\n",
    "    predict_labels.append(predict[i].index(max(predict[i])))\n",
    "print('Anger =',predict_labels.count(0))\n",
    "print('Calmness =',predict_labels.count(1))\n",
    "print('Disgust =',predict_labels.count(2))\n",
    "print('Fear =',predict_labels.count(3))\n",
    "print('Happiness =',predict_labels.count(4))\n",
    "print('Sadness =',predict_labels.count(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
